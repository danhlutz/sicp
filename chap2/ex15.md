# Comparing par1 and par2 for computing parallel resistance

# why does par2 produce tighter error bounds? 

For this exercise we will assume a resistor x with error bound p and a resistor y with error bound q

Using par1, the width of the tolerance reduces to:

0.5 * (- (/ (xy + xq + yp + pq)
            (x - p + y - q))
         (/ (xy - xq - yp + pq)
            (x + p + y + q)))

Using par2, the width of the tolerance reduces to:

0.5 * (- (/ (xy + xq + yp + pq)
            (x + p + y + q))
         (/ (xy - xq - yp + pq)
            (x - p + y - q)))

Basically, the denominator of the first expression has flipped from par1 to par2, while the numerator stays the same

(x + p + y + q) > (x - p + y - q)

In par1, you are dividing the first numerator by a smaller number, so the overall width of the error is bigger. par2 produces a smaller error bound because it divides the first numerator by the bigger number. 

The driving cause of the error being smaller is not that the first procedure repeats an uncertain number. It is because the process of division is repeated twice. When division is done once, the upper and lower bounds of the divisor are flipped and multiplied by the lower and upper bounds.

## Is tighter "better"? 

Alyssa claims that a smaller error bound is "better", but for many applications the engineer may prefer a wider error bound. A wide error, produced by procedure par1, would alert her to use resistors with tigheter error tolerance. par2 could give her a false sense of confidence.
